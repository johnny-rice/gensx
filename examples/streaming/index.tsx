import { ChatCompletion, OpenAIProvider } from "@gensx/openai";
import { gsx, Streamable } from "gensx";

async function runStreamingWithChildrenExample() {
  const prompt =
    "Write a 250 word story about an AI that discovers the meaning of friendship through a series of small interactions with humans. Be concise but meaningful.";

  console.log("\nüöÄ Starting streaming example with prompt:", prompt);

  console.log("\nüìù Non-streaming version (waiting for full response):");
  await gsx.execute<string>(
    <OpenAIProvider apiKey={process.env.OPENAI_API_KEY}>
      <ChatCompletion
        model="gpt-4o-mini"
        messages={[{ role: "user", content: prompt }]}
      >
        {(response: string) => {
          console.log(response);
        }}
      </ChatCompletion>
    </OpenAIProvider>,
  );

  console.log("\nüìù Streaming version (processing tokens as they arrive):");
  await gsx.execute(
    <OpenAIProvider apiKey={process.env.OPENAI_API_KEY}>
      <ChatCompletion
        model="gpt-4o-mini"
        stream={true}
        messages={[{ role: "user", content: prompt }]}
      >
        {async (response: Streamable) => {
          // Print tokens as they arrive
          for await (const token of response) {
            process.stdout.write(token);
          }
          process.stdout.write("\n");
          console.log("‚úÖ Streaming complete");
        }}
      </ChatCompletion>
    </OpenAIProvider>,
  );
}

async function runStreamingExample() {
  const prompt =
    "Write a 250 word story about an AI that discovers the meaning of friendship through a series of small interactions with humans. Be concise but meaningful.";

  console.log("\nüöÄ Starting streaming example with prompt:", prompt);

  console.log("\nüìù Non-streaming version (waiting for full response):");
  const finalResult = await gsx.execute<string>(
    <OpenAIProvider apiKey={process.env.OPENAI_API_KEY}>
      <ChatCompletion
        model="gpt-4o-mini"
        messages={[{ role: "user", content: prompt }]}
      />
    </OpenAIProvider>,
  );
  console.log("‚úÖ Complete response:", finalResult);

  console.log("\nüìù Streaming version (processing tokens as they arrive):");
  const response = await gsx.execute<Streamable>(
    <OpenAIProvider apiKey={process.env.OPENAI_API_KEY}>
      <ChatCompletion
        model="gpt-4o-mini"
        stream={true}
        messages={[{ role: "user", content: prompt }]}
      />
    </OpenAIProvider>,
  );

  for await (const token of response) {
    process.stdout.write(token);
  }
  process.stdout.write("\n");
  console.log("‚úÖ Streaming complete");
}

const GeneratorComponent = gsx.StreamComponent<{
  foo: string;
  iterations: number;
}>("GeneratorComponent", function* ({ foo, iterations }) {
  for (let i = 1; i < iterations + 1; i++) {
    console.log("üî• GeneratorComponent", i);
    yield `${i}: ${foo.repeat(i)}\n`;
  }
});

async function streamingGeneratorExample() {
  console.log("‚ö°Ô∏è StreamingGeneratorExample - return result from generator");
  const response1 = await gsx.execute<string>(
    <OpenAIProvider apiKey={process.env.OPENAI_API_KEY}>
      <GeneratorComponent foo="bar" iterations={10} />
    </OpenAIProvider>,
  );
  console.log(`‚úÖ Streaming complete:\n====\n${response1}====`);
  console.log("‚ö°Ô∏è StreamingGeneratorExample - process generator result");
  await gsx.execute<string>(
    <OpenAIProvider apiKey={process.env.OPENAI_API_KEY}>
      <GeneratorComponent stream={true} foo="bar" iterations={10}>
        {async (response: Streamable) => {
          for await (const token of response) {
            process.stdout.write(token);
          }
          process.stdout.write("\n");
          console.log("‚úÖ Streaming complete");
        }}
      </GeneratorComponent>
    </OpenAIProvider>,
  );
}

// Main function to run examples
async function main() {
  await runStreamingWithChildrenExample();
  await runStreamingExample();
  await streamingGeneratorExample();
}

main().catch(console.error);

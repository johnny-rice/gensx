---
title: Anthropic
description: Anthropic API compatible component reference
---

# Anthropic

The [@gensx/anthropic](https://www.npmjs.com/package/@gensx/anthropic) package provides [Anthropic API](https://docs.anthropic.com/en/api/getting-started) compatible components for GenSX.

## Installation

To install the package, run the following command:

```bash
npm install @gensx/anthropic
```

Then import the components you need from the package:

```tsx
import { AnthropicProvider, GSXChatCompletion } from "@gensx/anthropic";
```

## Supported components

| <div style={{width: "150px"}}>Component</div>         | Description                                                                           |
| :---------------------------------------------------- | :------------------------------------------------------------------------------------ |
| [`AnthropicProvider`](#anthropicprovider)             | Anthropic Provider that handles configuration and authentication for child components |
| [`GSXChatCompletion`](#gsxchatcompletion)             | Enhanced component with advanced features for Anthropic chat completions              |
| [`ChatCompletion`](#chatcompletion)                   | Simplified component for chat completions with streamlined output interface           |
| [`AnthropicChatCompletion`](#anthropicchatcompletion) | Low-level component that directly matches the Anthropic SDK interface                 |

## Component Comparison

The package provides three different chat completion components to suit different use cases:

- **AnthropicChatCompletion**: Direct mapping to the Anthropic API with identical inputs and outputs
- **GSXChatCompletion**: Enhanced component with additional features like structured output and automated tool calling
- **ChatCompletion**: Simplified interface that returns string responses or simple streams while maintaining identical inputs to the Anthropic API

## Reference

#### `<AnthropicProvider/>`

The `AnthropicProvider` component initializes and provides an Anthropic client instance to all child components. Any components that use Anthropic's API need to be wrapped in an `AnthropicProvider`.

```tsx
<AnthropicProvider
  apiKey="your-api-key" // Your Anthropic API key
/>
```

##### Props

The `AnthropicProvider` accepts all configuration options from the [Anthropic Node.js client library](https://github.com/anthropics/anthropic-sdk-typescript) including:

- `apiKey` (required): Your Anthropic API key
- Plus all other Anthropic client configuration options

#### `<GSXChatCompletion/>`

The `GSXChatCompletion` component is an advanced chat completion component that provides enhanced features beyond the standard Anthropic API. It supports structured output, tool calling, and streaming, with automatic handling of tool execution.

To get a structured output, pass a [Zod schema](https://www.npmjs.com/package/zod) to the `outputSchema` prop.

```tsx
// Returns an object matching the outputSchema when executed
<GSXChatCompletion
  model="claude-3-7-sonnet-latest"
  system="You are a helpful assistant."
  messages={[
    {
      role: "user",
      content: "Extract the name and age from: John Doe, 32 years old",
    },
  ]}
  outputSchema={z.object({
    name: z.string(),
    age: z.number(),
  })}
  max_tokens={1000}
/>
```

To use tools, create a `GSXTool` object:

```tsx
const weatherTool = GSXTool.create({
  name: "get_weather",
  description: "Get the weather for a given location",
  schema: z.object({
    location: z.string(),
  }),
  run: async ({ location }) => {
    return { weather: "sunny" };
  },
});
```

Then pass the tool to the `tools` prop.

```tsx
<GSXChatCompletion
  model="claude-3-7-sonnet-latest"
  system="You are a helpful assistant."
  messages={[{ role: "user", content: "What's the weather in Seattle?" }]}
  tools={[weatherTool]}
  max_tokens={1000}
/>
```

##### Props

The `GSXChatCompletion` component accepts all parameters from Anthropic's messages API plus additional options:

- `model` (required): ID of the model to use (e.g., `"claude-3-7-sonnet-latest"`, `"claude-3-5-haiku-latest"`)
- `messages` (required): Array of messages in the conversation
- `max_tokens` (required): Maximum number of tokens to generate
- `system`: System prompt to set the behavior of the assistant
- `stream`: Whether to stream the response (when `true`, returns a `Stream<RawMessageStreamEvent>`)
- `tools`: Array of `GSXTool` instances for function calling
- `outputSchema`: Zod schema for structured output (when provided, returns data matching the schema)
- `temperature`: Sampling temperature
- Plus all standard Anthropic message parameters

##### Return Types

The return type of `GSXChatCompletion` depends on the props:

- With `stream: true`: Returns `Stream<RawMessageStreamEvent>` from Anthropic SDK
- With `outputSchema`: Returns data matching the provided Zod schema
- Default: Returns `GSXChatCompletionResult` (Anthropic response with message history)

#### `<ChatCompletion/>`

The `ChatCompletion` component provides a simplified interface for chat completions. It returns either a string or a simple stream of string tokens while having identical inputs to the Anthropic API.

```tsx
// Returns a string when executed
<ChatCompletion
  model="claude-3-7-sonnet-latest"
  system="You are a helpful assistant."
  messages={[{ role: "user", content: "What's a programmable tree?" }]}
  temperature={0.7}
  max_tokens={1000}
/>

// Returns an AsyncIterableIterator<string> when executed
<ChatCompletion
  model="claude-3-7-sonnet-latest"
  system="You are a helpful assistant."
  messages={[{ role: "user", content: "What's a programmable tree?" }]}
  temperature={0.7}
  max_tokens={1000}
  stream={true}
/>
```

##### Props

The `ChatCompletion` component accepts all parameters from Anthropic's messages API:

- `model` (required): ID of the model to use (e.g., `"claude-3-5-sonnet-latest"`, `"claude-3-haiku-latest"`)
- `messages` (required): Array of messages in the conversation
- `max_tokens` (required): Maximum number of tokens to generate
- `system`: System prompt to set the behavior of the assistant
- `temperature`: Sampling temperature
- `stream`: Whether to stream the response
- `tools`: Array of `GSXTool` instances for function calling (not compatible with streaming)

##### Return Types

- With `stream: false` (default): Returns a string containing the model's response
- With `stream: true`: Returns an `AsyncIterableIterator<string>` that yields tokens as they're generated

#### `<AnthropicChatCompletion/>`

The `AnthropicChatCompletion` component is a low-level component that directly maps to the Anthropic SDK. It has identical inputs and outputs to the Anthropic API, making it suitable for advanced use cases where you need full control.

```tsx
<AnthropicChatCompletion
  model="claude-3-7-sonnet-latest"
  system="You are a helpful assistant."
  messages={[{ role: "user", content: "What's a programmable tree?" }]}
  max_tokens={1000}
/>
```

##### Props

The `AnthropicChatCompletion` component accepts all parameters from the Anthropic SDK's `messages.create` method:

- `model` (required): ID of the model to use
- `messages` (required): Array of messages in the conversation
- `max_tokens` (required): Maximum number of tokens to generate
- `system`: System prompt to set the behavior of the assistant
- `temperature`: Sampling temperature
- `stream`: Whether to stream the response
- `tools`: Array of Anthropic tool definitions for function calling
- Plus all other Anthropic message parameters

##### Return Types

- With `stream: false` (default): Returns the full `Message` object from Anthropic SDK
- With `stream: true`: Returns a `Stream<RawMessageStreamEvent>` from Anthropic SDK
